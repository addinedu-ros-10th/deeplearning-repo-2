import torch
import torch.nn as nn
import numpy as np
import cv2
from collections import deque
import threading
import time

# --- 1. ì„¤ì • ë° ëª¨ë¸ êµ¬ì¡° ì •ì˜ ---
MODEL_PATH = '/home/momo/Desktop/video/action_model.pt'
FIXED_FRAMES = 64 
CLASSES = {0: 'Normal', 1: 'Dumping Detected'}

# í•™ìŠµ ë•Œ ì‚¬ìš©í–ˆë˜ ëª¨ë¸ í´ë˜ìŠ¤
class ActionClassifier(nn.Module):
    def __init__(self):
        super(ActionClassifier, self).__init__()
        self.conv3d = nn.Conv3d(in_channels=3, out_channels=16, kernel_size=(3, 3, 3), padding=1)
        self.relu = nn.ReLU()
        self.pool = nn.MaxPool3d(kernel_size=(2, 2, 2))
        final_feature_size = 16 * (FIXED_FRAMES // 2) * (224 // 2) * (224 // 2)
        self.fc1 = nn.Linear(final_feature_size, 2)

    def forward(self, x):
        x = self.pool(self.relu(self.conv3d(x)))
        x = x.view(x.size(0), -1) 
        x = self.fc1(x)
        return x

# --- 2. ëª¨ë¸ ë¡œë“œ ---
device = torch.device('cpu')
model = ActionClassifier()
model.load_state_dict(torch.load(MODEL_PATH, map_location=device))
model.to(device)
model.eval()
print("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ.")

# --- 3. ìŠ¤ë ˆë“œ ê°„ ê³µìœ í•  ë³€ìˆ˜ ---
frame_buffer = deque(maxlen=FIXED_FRAMES)
prediction_text = "Initializing..."
lock = threading.Lock() # ë³€ìˆ˜ ì ‘ê·¼ì„ ë™ê¸°í™”í•˜ê¸° ìœ„í•œ Lock
is_running = True

# --- 4. ì¶”ë¡  ìŠ¤ë ˆë“œ í•¨ìˆ˜ ---
def run_inference():
    global prediction_text, is_running, frame_buffer
    
    while is_running:
        if len(frame_buffer) == FIXED_FRAMES:
            # ë²„í¼ ë³µì‚¬í•˜ì—¬ ì¶”ë¡  ì¤‘ ë²„í¼ê°€ ë³€ê²½ë˜ì–´ë„ ë¬¸ì œ ì—†ë„ë¡ í•¨
            buffer_copy = list(frame_buffer)
            
            clip = np.array(buffer_copy)
            clip_tensor = torch.tensor(clip, dtype=torch.float32).permute(3, 0, 1, 2)
            clip_tensor = clip_tensor.unsqueeze(0).to(device)

            with torch.no_grad():
                outputs = model(clip_tensor)
                _, predicted_idx = torch.max(outputs, 1)
                
                # Lockì„ ì‚¬ìš©í•˜ì—¬ ê³µìœ  ë³€ìˆ˜ë¥¼ ì•ˆì „í•˜ê²Œ ì—…ë°ì´íŠ¸
                with lock:
                    prediction_text = CLASSES[predicted_idx.item()]
        
        # ì¶”ë¡  ìŠ¤ë ˆë“œê°€ ë„ˆë¬´ ë¹ ë¥´ê²Œ ë°˜ë³µë˜ëŠ” ê²ƒì„ ë°©ì§€
        time.sleep(0.1) 

# --- 5. ë©”ì¸ ìŠ¤ë ˆë“œ (ì¹´ë©”ë¼ ë° ë””ìŠ¤í”Œë ˆì´) ---
print("ğŸš€ ì‹¤ì‹œê°„ íƒì§€ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
cap = cv2.VideoCapture(0)

# ì¶”ë¡  ìŠ¤ë ˆë“œ ì‹œì‘
inference_thread = threading.Thread(target=run_inference, daemon=True)
inference_thread.start()

while True:
    ret, frame = cap.read()
    if not ret:
        print("âŒ ì¹´ë©”ë¼ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        break

    # í”„ë ˆì„ ì „ì²˜ë¦¬ ë° ë²„í¼ì— ì¶”ê°€ (ì´ ì‘ì—…ì€ ë¹ ë¦„)
    resized_frame = cv2.resize(frame, (224, 224))
    normalized_frame = resized_frame / 255.0
    frame_buffer.append(normalized_frame)

    # Lockì„ ì‚¬ìš©í•˜ì—¬ ì¶”ë¡  ìŠ¤ë ˆë“œê°€ ì—…ë°ì´íŠ¸í•œ ê²°ê³¼ë¥¼ ì•ˆì „í•˜ê²Œ ì½ì–´ì˜¤ê¸°
    with lock:
        display_text = prediction_text
    
    color = (0, 255, 0) # ì´ˆë¡ìƒ‰ (Normal)
    if display_text == 'Dumping Detected':
        color = (0, 0, 255) # ë¹¨ê°„ìƒ‰ (Dumping)

    cv2.putText(frame, display_text, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.5, color, 3)
    cv2.imshow('Real-time Dumping Detection (Threaded)', frame)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# --- 6. ì¢…ë£Œ ì²˜ë¦¬ ---
print("ì¢…ë£Œ ì¤‘...")
is_running = False # ì¶”ë¡  ìŠ¤ë ˆë“œ ì¢…ë£Œ ì‹ í˜¸
inference_thread.join(timeout=1) # ìŠ¤ë ˆë“œê°€ ì¢…ë£Œë  ë•Œê¹Œì§€ ì ì‹œ ëŒ€ê¸°
cap.release()
cv2.destroyAllWindows()