{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3efef61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting roboflow\n",
      "  Downloading roboflow-1.2.9-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting certifi (from roboflow)\n",
      "  Downloading certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting idna==3.7 (from roboflow)\n",
      "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting cycler (from roboflow)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from roboflow)\n",
      "  Downloading kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\n",
      "Collecting matplotlib (from roboflow)\n",
      "  Downloading matplotlib-3.10.6-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /home/momo/venv/DEEP_REPO_2/lib/python3.12/site-packages (from roboflow) (2.1.2)\n",
      "Collecting opencv-python-headless==4.10.0.84 (from roboflow)\n",
      "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in /home/momo/venv/DEEP_REPO_2/lib/python3.12/site-packages (from roboflow) (11.0.0)\n",
      "Collecting pi-heif<2 (from roboflow)\n",
      "  Downloading pi_heif-1.1.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.5 kB)\n",
      "Collecting pillow-avif-plugin<2 (from roboflow)\n",
      "  Downloading pillow_avif_plugin-1.5.2-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: python-dateutil in /home/momo/venv/DEEP_REPO_2/lib/python3.12/site-packages (from roboflow) (2.9.0.post0)\n",
      "Collecting python-dotenv (from roboflow)\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting requests (from roboflow)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: six in /home/momo/venv/DEEP_REPO_2/lib/python3.12/site-packages (from roboflow) (1.17.0)\n",
      "Collecting urllib3>=1.26.6 (from roboflow)\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /home/momo/venv/DEEP_REPO_2/lib/python3.12/site-packages (from roboflow) (4.67.1)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /home/momo/venv/DEEP_REPO_2/lib/python3.12/site-packages (from roboflow) (6.0.3)\n",
      "Collecting requests-toolbelt (from roboflow)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting filetype (from roboflow)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting Pillow>=7.1.2 (from roboflow)\n",
      "  Downloading pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->roboflow)\n",
      "  Downloading contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->roboflow)\n",
      "  Downloading fonttools-4.60.0-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (111 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.6/111.6 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /home/momo/venv/DEEP_REPO_2/lib/python3.12/site-packages (from matplotlib->roboflow) (25.0)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib->roboflow)\n",
      "  Downloading pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->roboflow)\n",
      "  Downloading charset_normalizer-3.4.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (36 kB)\n",
      "Downloading roboflow-1.2.9-py3-none-any.whl (88 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.7/88.7 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pi_heif-1.1.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading pillow_avif_plugin-1.5.2-cp312-cp312-manylinux_2_28_x86_64.whl (4.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.8/129.8 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.2/161.2 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading matplotlib-3.10.6-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m80.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading charset_normalizer-3.4.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (151 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.8/151.8 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (362 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.6/362.6 kB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fonttools-4.60.0-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m116.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.9/113.9 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pillow-avif-plugin, filetype, urllib3, python-dotenv, pyparsing, Pillow, opencv-python-headless, kiwisolver, idna, fonttools, cycler, contourpy, charset_normalizer, certifi, requests, pi-heif, matplotlib, requests-toolbelt, roboflow\n",
      "  Attempting uninstall: Pillow\n",
      "    Found existing installation: pillow 11.0.0\n",
      "    Uninstalling pillow-11.0.0:\n",
      "      Successfully uninstalled pillow-11.0.0\n",
      "Successfully installed Pillow-11.3.0 certifi-2025.8.3 charset_normalizer-3.4.3 contourpy-1.3.3 cycler-0.12.1 filetype-1.2.0 fonttools-4.60.0 idna-3.7 kiwisolver-1.4.9 matplotlib-3.10.6 opencv-python-headless-4.10.0.84 pi-heif-1.1.0 pillow-avif-plugin-1.5.2 pyparsing-3.2.5 python-dotenv-1.1.1 requests-2.32.5 requests-toolbelt-1.0.0 roboflow-1.2.9 urllib3-2.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "780b1cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Littering--8 to yolov8:: 100%|██████████| 4185630/4185630 [02:57<00:00, 23618.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to Littering--8 in yolov8:: 100%|██████████| 34812/34812 [00:05<00:00, 6380.92it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "다운로드가 완료되었습니다!\n",
      "데이터셋 경로: /home/momo/dev_ws/deeplearning-repo-2/situationDetector/detect/feat_detect_trash/Littering--8\n"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "\n",
    "# 1. Roboflow 객체를 생성합니다. private \n",
    "rf = Roboflow(api_key=\"nFnxZrCzerTLs32hyCGD\")\n",
    "\n",
    "# 2. 다운로드할 프로젝트 정보를 입력합니다.\n",
    "#    URL: https://universe.roboflow.com/thesis-kztn8/littering-whlsk\n",
    "#    - workspace: \"thesis-kztn8\"\n",
    "#    - project: \"littering-whlsk\"\n",
    "#    - version: 1 (다운로드하려는 데이터셋 버전 번호)\n",
    "project = rf.workspace(\"thesis-kztn8\").project(\"littering-whlsk\")\n",
    "version = project.version(8)\n",
    "\n",
    "# 3. 데이터를 YOLOv8 형식으로 다운로드합니다.\n",
    "dataset = version.download(\"yolov8\")\n",
    "\n",
    "print(\"\\n다운로드가 완료되었습니다!\")\n",
    "print(f\"데이터셋 경로: {dataset.location}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "360b53f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.203-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: pyyaml in /home/momo/venv/DEEP_REPO_2/lib/python3.12/site-packages (6.0.3)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /home/momo/venv/DEEP_REPO_2/lib/python3.12/site-packages (from ultralytics) (2.1.2)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /home/momo/venv/DEEP_REPO_2/lib/python3.12/site-packages (from ultralytics) (3.10.6)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /home/momo/venv/DEEP_REPO_2/lib/python3.12/site-packages (from ultralytics) (4.12.0.88)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /home/momo/venv/DEEP_REPO_2/lib/python3.12/site-packages (from ultralytics) (11.3.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in /home/momo/venv/DEEP_REPO_2/lib/python3.12/site-packages (from ultralytics) (2.32.5)\n",
      "Collecting scipy>=1.4.1 (from ultralytics)\n",
      "  Downloading scipy-1.16.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (62 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.8.0 in /home/momo/venv/DEEP_REPO_2/lib/python3.12/site-packages (from ultralytics) (2.7.1+cu118)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /home/momo/venv/DEEP_REPO_2/lib/python3.12/site-packages (from ultralytics) (0.22.1+cu118)\n",
      "Requirement already satisfied: psutil in /home/momo/venv/DEEP_REPO_2/lib/python3.12/site-packages (from ultralytics) (7.1.0)\n",
      "Collecting polars (from ultralytics)\n",
      "  Downloading polars-1.33.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
      "  Downloading ultralytics_thop-2.0.17-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/momo/venv/DEEP_REPO_2/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/momo/venv/DEEP_REPO_2/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/momo/venv/DEEP_REPO_2/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (4.60.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/momo/venv/DEEP_REPO_2/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/momo/venv/DEEP_REPO_2/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/momo/venv/DEEP_REPO_2/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/momo/venv/DEEP_REPO_2/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/momo/venv/DEEP_REPO_2/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/momo/venv/DEEP_REPO_2/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/momo/venv/DEEP_REPO_2/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/momo/venv/DEEP_REPO_2/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (2025.8.3)\n",
      "Requirement already satisfied: filelock in /home/momo/venv/DEEP_REPO_2/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/momo/venv/DEEP_REPO_2/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: setuptools in /home/momo/venv/DEEP_REPO_2/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (70.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/momo/venv/DEEP_REPO_2/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/momo/venv/DEEP_REPO_2/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/momo/venv/DEEP_REPO_2/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/momo/venv/DEEP_REPO_2/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /home/momo/venv/DEEP_REPO_2/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /home/momo/venv/DEEP_REPO_2/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /home/momo/venv/DEEP_REPO_2/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (11.8.87)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /home/momo/venv/DEEP_REPO_2/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /home/momo/venv/DEEP_REPO_2/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (11.11.3.6)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/momo/venv/DEEP_REPO_2/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /home/momo/venv/DEEP_REPO_2/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (10.3.0.86)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /home/momo/venv/DEEP_REPO_2/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (11.4.1.48)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /home/momo/venv/DEEP_REPO_2/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (11.7.5.86)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /home/momo/venv/DEEP_REPO_2/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /home/momo/venv/DEEP_REPO_2/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (11.8.86)\n",
      "Requirement already satisfied: triton==3.3.1 in /home/momo/venv/DEEP_REPO_2/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.3.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/momo/venv/DEEP_REPO_2/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/momo/venv/DEEP_REPO_2/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/momo/venv/DEEP_REPO_2/lib/python3.12/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
      "Downloading ultralytics-8.3.203-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.16.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0mm\n",
      "\u001b[?25hDownloading ultralytics_thop-2.0.17-py3-none-any.whl (28 kB)\n",
      "Downloading polars-1.33.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.7/39.7 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: scipy, polars, ultralytics-thop, ultralytics\n",
      "Successfully installed polars-1.33.1 scipy-1.16.2 ultralytics-8.3.203 ultralytics-thop-2.0.17\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics pyyaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6225383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- data.yaml 파일 내용 ---\n",
      "{'names': ['dumping'], 'nc': 1, 'roboflow': {'license': 'CC BY 4.0', 'project': 'littering-whlsk', 'url': 'https://universe.roboflow.com/thesis-kztn8/littering-whlsk/dataset/8', 'version': 8, 'workspace': 'thesis-kztn8'}, 'train': '/home/momo/Desktop/dataset/thesis-kztn8_littering-whlsk(8)/Littering--8/train/images', 'val': '/home/momo/Desktop/dataset/thesis-kztn8_littering-whlsk(8)/Littering--8/valid/images', 'test': '/home/momo/Desktop/dataset/thesis-kztn8_littering-whlsk(8)/Littering--8/test/images'}\n",
      "---------------------------\n",
      "\n",
      "Checking train path: /home/momo/Desktop/dataset/thesis-kztn8_littering-whlsk(8)/Littering--8/train/images\n",
      "Checking val path: /home/momo/Desktop/dataset/thesis-kztn8_littering-whlsk(8)/Littering--8/valid/images\n",
      "Checking test path: /home/momo/Desktop/dataset/thesis-kztn8_littering-whlsk(8)/Littering--8/test/images\n",
      "Updated data.yaml with absolute paths.\n",
      "YOLOv8n 모델을 불러옵니다...\n",
      "\n",
      "모델 훈련을 시작합니다...\n",
      "Ultralytics 8.3.203 🚀 Python-3.12.3 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 2060, 5739MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/home/momo/Desktop/dataset/thesis-kztn8_littering-whlsk(8)/Littering--8/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8n_littering_detector, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/home/momo/dev_ws/deeplearning-repo-2/situationDetector/detect/feat_detect_trash/runs/detect/yolov8n_littering_detector, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1101.8±1570.0 MB/s, size: 208.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/momo/Desktop/dataset/thesis-kztn8_littering-whlsk(8)/Littering--8/train/labels.cache... 15000 images, 2 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 15000/15000 39.0Mit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1108.6±1082.9 MB/s, size: 278.9 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/momo/Desktop/dataset/thesis-kztn8_littering-whlsk(8)/Littering--8/valid/labels.cache... 1168 images, 1 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 1168/1168 1.0Mit/s 0.0ss\n",
      "Plotting labels to /home/momo/dev_ws/deeplearning-repo-2/situationDetector/detect/feat_detect_trash/runs/detect/yolov8n_littering_detector/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/momo/dev_ws/deeplearning-repo-2/situationDetector/detect/feat_detect_trash/runs/detect/yolov8n_littering_detector\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      1/100       3.7G      1.165      1.828      1.059         14        640: 100% ━━━━━━━━━━━━ 938/938 6.5it/s 2:25<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 7.0it/s 5.3s0.1s\n",
      "                   all       1168       1167      0.282      0.453      0.259       0.13\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      2/100       3.7G      1.088      1.134      1.045         17        640: 100% ━━━━━━━━━━━━ 938/938 6.9it/s 2:15<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 9.1it/s 4.1s0.1s\n",
      "                   all       1168       1167      0.527      0.796      0.517      0.332\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      3/100       3.7G      1.108       1.04       1.07         14        640: 100% ━━━━━━━━━━━━ 938/938 7.0it/s 2:14<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 9.2it/s 4.0s0.1s\n",
      "                   all       1168       1167      0.479      0.771      0.485      0.288\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      4/100      3.71G       1.11      1.015      1.084         18        640: 100% ━━━━━━━━━━━━ 938/938 7.0it/s 2:13<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 9.2it/s 4.0s0.1s\n",
      "                   all       1168       1167      0.462      0.685      0.427      0.259\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      5/100       3.7G       1.04     0.9071      1.055         17        640: 100% ━━━━━━━━━━━━ 938/938 7.0it/s 2:13<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 9.4it/s 3.9s0.1s\n",
      "                   all       1168       1167      0.518      0.754      0.558      0.369\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      6/100       3.7G     0.9936     0.8462      1.032         19        640: 100% ━━━━━━━━━━━━ 938/938 7.0it/s 2:13<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 9.2it/s 4.0s0.1s\n",
      "                   all       1168       1167      0.458      0.636      0.416      0.265\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      7/100       3.7G     0.9578      0.796      1.016         20        640: 100% ━━━━━━━━━━━━ 938/938 7.0it/s 2:14<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 9.3it/s 4.0s0.1s\n",
      "                   all       1168       1167      0.591      0.795      0.623      0.417\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      8/100      3.71G     0.9231     0.7591      1.002         14        640: 100% ━━━━━━━━━━━━ 938/938 7.0it/s 2:13<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 9.5it/s 3.9s0.1s\n",
      "                   all       1168       1167      0.527      0.769      0.538      0.342\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      9/100       3.7G     0.8946     0.7298     0.9913         19        640: 100% ━━━━━━━━━━━━ 938/938 7.0it/s 2:13<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 9.5it/s 3.9s0.1s\n",
      "                   all       1168       1167      0.558      0.709      0.563      0.376\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     10/100       3.7G     0.8776     0.7046     0.9836         12        640: 100% ━━━━━━━━━━━━ 938/938 7.0it/s 2:13<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 9.4it/s 3.9s0.1s\n",
      "                   all       1168       1167      0.552      0.761      0.573      0.368\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     11/100       3.7G     0.8593     0.6831     0.9789         16        640: 100% ━━━━━━━━━━━━ 938/938 7.0it/s 2:13<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 9.4it/s 3.9s0.1s\n",
      "                   all       1168       1167      0.537      0.772      0.565      0.374\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     12/100       3.7G     0.8381     0.6617     0.9688         13        640: 100% ━━━━━━━━━━━━ 938/938 7.0it/s 2:13<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 9.4it/s 3.9s0.1s\n",
      "                   all       1168       1167      0.501      0.807      0.514      0.324\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     13/100       3.7G     0.8257     0.6397     0.9634         14        640: 100% ━━━━━━━━━━━━ 938/938 7.0it/s 2:14<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 9.3it/s 4.0s0.1s\n",
      "                   all       1168       1167      0.502      0.762      0.505       0.34\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     14/100       3.7G     0.8146     0.6295     0.9624         16        640: 100% ━━━━━━━━━━━━ 938/938 6.8it/s 2:18<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 6.1it/s 6.0s0.2s\n",
      "                   all       1168       1167       0.53       0.76      0.521      0.353\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     15/100       3.7G     0.7986     0.6213     0.9559         13        640: 100% ━━━━━━━━━━━━ 938/938 6.8it/s 2:18<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 9.3it/s 4.0s0.1s\n",
      "                   all       1168       1167      0.504       0.75       0.49      0.319\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     16/100       3.7G     0.7922     0.6128     0.9521         17        640: 100% ━━━━━━━━━━━━ 938/938 7.1it/s 2:12<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 9.7it/s 3.8s0.1s\n",
      "                   all       1168       1167      0.517      0.783      0.558      0.357\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     17/100       3.7G     0.7815     0.5977     0.9502         14        640: 100% ━━━━━━━━━━━━ 938/938 7.1it/s 2:12<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 9.6it/s 3.9s0.1s\n",
      "                   all       1168       1167      0.507      0.742      0.513      0.341\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     18/100       3.7G     0.7657     0.5838     0.9415         12        640: 100% ━━━━━━━━━━━━ 938/938 7.1it/s 2:12<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 9.7it/s 3.8s0.1s\n",
      "                   all       1168       1167      0.521      0.698      0.522       0.34\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     19/100       3.7G     0.7618     0.5755     0.9421         16        640: 100% ━━━━━━━━━━━━ 938/938 7.1it/s 2:12<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 9.7it/s 3.8s0.1s\n",
      "                   all       1168       1167      0.459       0.71      0.499      0.341\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     20/100      3.71G     0.7498     0.5684     0.9364         14        640: 100% ━━━━━━━━━━━━ 938/938 7.1it/s 2:12<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 9.6it/s 3.9s0.1s\n",
      "                   all       1168       1167      0.486      0.651      0.464      0.292\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     21/100       3.7G     0.7438     0.5623     0.9354         13        640: 100% ━━━━━━━━━━━━ 938/938 7.1it/s 2:12<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 9.5it/s 3.9s0.1s\n",
      "                   all       1168       1167      0.513      0.734      0.527      0.364\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     22/100       3.7G     0.7403     0.5571     0.9338         13        640: 100% ━━━━━━━━━━━━ 938/938 7.1it/s 2:12<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 9.6it/s 3.8s0.1s\n",
      "                   all       1168       1167      0.476      0.675      0.443      0.294\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     23/100       3.7G     0.7297     0.5454     0.9293         21        640: 100% ━━━━━━━━━━━━ 938/938 7.1it/s 2:13<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 9.3it/s 4.0s0.1s\n",
      "                   all       1168       1167      0.451      0.718      0.482      0.329\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     24/100       3.7G     0.7238     0.5393     0.9277         13        640: 100% ━━━━━━━━━━━━ 938/938 7.1it/s 2:12<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 9.5it/s 3.9s0.1s\n",
      "                   all       1168       1167      0.455      0.658      0.427      0.287\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     25/100       3.7G     0.7197     0.5379     0.9279         13        640: 100% ━━━━━━━━━━━━ 938/938 7.1it/s 2:12<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 9.7it/s 3.8s0.1s\n",
      "                   all       1168       1167       0.43      0.626      0.405      0.271\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     26/100      3.71G      0.711     0.5269     0.9219         22        640: 100% ━━━━━━━━━━━━ 938/938 6.6it/s 2:23<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 9.1it/s 4.1s0.1s\n",
      "                   all       1168       1167       0.48      0.734      0.487      0.333\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     27/100       3.7G     0.7054     0.5218     0.9203         13        640: 100% ━━━━━━━━━━━━ 938/938 7.0it/s 2:14<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 9.2it/s 4.0s0.1s\n",
      "                   all       1168       1167      0.448      0.656      0.463       0.32\n",
      "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 20 epochs. Best results observed at epoch 7, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=20) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
      "\n",
      "27 epochs completed in 1.041 hours.\n",
      "Optimizer stripped from /home/momo/dev_ws/deeplearning-repo-2/situationDetector/detect/feat_detect_trash/runs/detect/yolov8n_littering_detector/weights/last.pt, 6.2MB\n",
      "Optimizer stripped from /home/momo/dev_ws/deeplearning-repo-2/situationDetector/detect/feat_detect_trash/runs/detect/yolov8n_littering_detector/weights/best.pt, 6.2MB\n",
      "\n",
      "Validating /home/momo/dev_ws/deeplearning-repo-2/situationDetector/detect/feat_detect_trash/runs/detect/yolov8n_littering_detector/weights/best.pt...\n",
      "Ultralytics 8.3.203 🚀 Python-3.12.3 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 2060, 5739MiB)\n",
      "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 37/37 7.0it/s 5.3s0.1s\n",
      "                   all       1168       1167      0.592      0.796      0.623      0.417\n",
      "Speed: 0.1ms preprocess, 1.2ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1m/home/momo/dev_ws/deeplearning-repo-2/situationDetector/detect/feat_detect_trash/runs/detect/yolov8n_littering_detector\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "# --- 중요 ---\n",
    "# 이 스크립트를 실행하기 전에, 'download_dataset.py'를 먼저 실행하여\n",
    "# 데이터셋 폴더가 생성되었는지 확인해야 합니다.\n",
    "\n",
    "# 2. 데이터셋 설정 파일(YAML) 경로 확인\n",
    "# Roboflow에서 다운로드하면 자동으로 생성되는 설정 파일입니다.\n",
    "DATASET_DIR = '/home/momo/Desktop/dataset/thesis-kztn8_littering-whlsk(8)/Littering--8' #<-- 'littering-whlsk-1'에서 수정됨\n",
    "data_yaml_path = os.path.join(DATASET_DIR, 'data.yaml')\n",
    "\n",
    "# YAML 파일 내용을 확인하여 경로와 클래스가 올바른지 살펴봅니다.\n",
    "try:\n",
    "    with open(data_yaml_path, 'r') as f:\n",
    "        data_yaml = yaml.safe_load(f)\n",
    "        print(\"--- data.yaml 파일 내용 ---\")\n",
    "        print(data_yaml)\n",
    "        print(\"---------------------------\\n\")\n",
    "        \n",
    "        # Check if paths exist before training\n",
    "        for split in ['train', 'val', 'test']:\n",
    "            if data_yaml.get(split):\n",
    "                abs_path = os.path.abspath(os.path.join(DATASET_DIR, data_yaml[split]))\n",
    "                data_yaml[split] = abs_path\n",
    "                print(f\"Checking {split} path: {abs_path}\")\n",
    "                if not os.path.exists(abs_path):\n",
    "                    print(f\"Error: {split} path does not exist: {abs_path}\")\n",
    "                    exit(1)\n",
    "        \n",
    "        with open(data_yaml_path, 'w') as f:\n",
    "            yaml.dump(data_yaml, f)\n",
    "            print(\"Updated data.yaml with absolute paths.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"오류: '{data_yaml_path}' 파일을 찾을 수 없습니다.\")\n",
    "    print(\"데이터셋 폴더 이름이 'Littering--8'이 맞는지, 'download_dataset.py'를 먼저 실행했는지 확인해주세요.\")\n",
    "    exit(1)\n",
    "\n",
    "# 3. YOLOv8 모델 불러오기\n",
    "# 가장 작고 빠른 yolov8n (nano) 모델로 시작합니다.\n",
    "print(\"YOLOv8n 모델을 불러옵니다...\")\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "\n",
    "# 4. 모델 훈련 시작\n",
    "# epochs: 전체 데이터셋을 몇 번 반복 학습할지 결정 (100번으로 시작)\n",
    "# imgsz: 훈련에 사용할 이미지 크기 (640x640)\n",
    "# patience: 지정된 epoch 동안 성능 향상이 없으면 훈련을 조기 종료 (과적합 방지)\n",
    "print(\"\\n모델 훈련을 시작합니다...\")\n",
    "results = model.train(\n",
    "    data=data_yaml_path,\n",
    "    epochs=100,\n",
    "    imgsz=640,\n",
    "    patience=20,\n",
    "    name='yolov8n_littering_detector' # 훈련 결과가 저장될 폴더 이름\n",
    ")\n",
    "\n",
    "print(\"\\n훈련이 완료되었습니다!\")\n",
    "print(\"결과는 'runs/detect/yolov8n_littering_detector' 폴더에 저장되었습니다.\")\n",
    "\n",
    "\n",
    "# 5. (선택) 훈련된 모델로 테스트 이미지 예측\n",
    "# 가장 성능이 좋았던 가중치(best.pt)를 사용하여 예측을 수행합니다.\n",
    "print(\"\\n훈련된 모델로 테스트 예측을 수행합니다...\")\n",
    "best_model_path = os.path.join('runs', 'detect', 'yolov8n_littering_detector', 'weights', 'best.pt')\n",
    "\n",
    "# 훈련된 모델이 존재하는지 확인\n",
    "if os.path.exists(best_model_path):\n",
    "    best_model = YOLO(best_model_path)\n",
    "    \n",
    "    test_images_path = data_yaml.get('test')\n",
    "\n",
    "    if test_images_path and os.path.exists(test_images_path):\n",
    "        # save=True 옵션으로 예측 결과(사각형이 그려진 이미지)를 저장합니다.\n",
    "        best_model.predict(\n",
    "            source=test_images_path,\n",
    "            save=True,\n",
    "            name='yolov8n_littering_prediction'\n",
    "        )\n",
    "\n",
    "        print(\"\\n예측이 완료되었습니다!\")\n",
    "        print(\"예측 결과 이미지는 'runs/detect/yolov8n_littering_prediction' 폴더에 저장되었습니다.\")\n",
    "    else:\n",
    "        print(\"테스트 이미지 경로를 찾을 수 없어 예측을 건너뜁니다.\")\n",
    "else:\n",
    "    print(f\"훈련된 모델 가중치({best_model_path})를 찾을 수 없어 예측을 건너뜁니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ef82ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638448dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dba8eb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476ac2a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1c948a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e74dff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19dbae6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e8408f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7cdc62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7705ab51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aced290",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322c2327",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a910c71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DEEP_REPO_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
